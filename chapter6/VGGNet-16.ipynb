{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_op(input_op, name, kh, kw, n_out, dh, dw, p):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "    \n",
    "\n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\",shape=[kh, kw, n_in, n_out],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        conv = tf.nn.conv2d(input_op, kernel, (1,dh,dw,1),padding='SAME')\n",
    "        bias_init_val = tf.constant(0.0,shape=[n_out],dtype=tf.float32)\n",
    "        biases = tf.Variable(bias_init_val,trainable=True,name='b')\n",
    "        z = tf.nn.bias_add(conv,biases)\n",
    "        activation = tf.nn.relu(z,name=scope)\n",
    "        p += [kernel, biases]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_op(input_op, name, n_out, p):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "    \n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\",shape=[n_in,n_out],dtype= tf.float32,initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(0.1,shape=[n_out],dtype=tf.float32),name='b')\n",
    "        avtivation = tf.nn.relu_layer(input_op,kernel,biases,name=scope)\n",
    "        p += [kernel,biases]\n",
    "        return avtivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mpool_op(input_op,name, kh,kw,dh,dw):\n",
    "    return tf.nn.max_pool(input_op,ksize=[1,kh,kw,1],strides=[1,dh,dw,1],padding='SAME',name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_op(input_op,keep_prob):\n",
    "    p = []\n",
    "    conv1_1 = conv_op(input_op,name=\"conv1_1\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
    "    conv1_2 = conv_op(conv1_1,name=\"conv1_2\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
    "    pool1 = mpool_op(conv1_2,name=\"pool1\",kh=2,kw=2,dw=2,dh=2)\n",
    "    \n",
    "    conv2_1 = conv_op(pool1,name=\"conv2_1\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
    "    conv2_2 = conv_op(conv2_1,name=\"conv2_2\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
    "    pool2 = mpool_op(conv2_2,name=\"pool2\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    conv3_1 = conv_op(pool2,name=\"conv3_1\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    conv3_2 = conv_op(conv3_1,name=\"conv3_2\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    conv3_3 = conv_op(conv3_2,name=\"conv3_3\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    pool3 = mpool_op(conv3_3,name=\"pool3\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    conv4_1 = conv_op(pool3,name=\"conv4_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv4_2 = conv_op(conv4_1,name=\"conv4_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv4_3 = conv_op(conv4_2,name=\"conv4_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    pool4 = mpool_op(conv4_3,name=\"pool4\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    conv5_1 = conv_op(pool4,name=\"conv5_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv5_2 = conv_op(conv5_1,name=\"conv5_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv5_3 = conv_op(conv5_2,name=\"conv5_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    pool5 = mpool_op(conv5_3,name=\"pool5\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    shp = pool5.get_shape()\n",
    "    flattened_shape = shp[1].value * shp[2].value * shp[3].value\n",
    "    resh1 = tf.reshape(pool5,[-1,flattened_shape],name=\"resh1\")\n",
    "    \n",
    "    fc6 = fc_op(resh1,name=\"fc6\",n_out=4096,p=p)\n",
    "    fc6_drop = tf.nn.dropout(fc6,keep_prob,name=\"fc6_drop\")\n",
    "    \n",
    "    fc7 = fc_op(fc6_drop,name=\"fc7\",n_out=4096,p=p)\n",
    "    fc7_drop = tf.nn.dropout(fc7,keep_prob,name=\"fc7_drop\")\n",
    "    \n",
    "    fc8 = fc_op(fc7_drop,name=\"fc8\",n_out=1000,p=p)\n",
    "    softmax=tf.nn.softmax(fc8)\n",
    "    predictions = tf.argmax(softmax,1)\n",
    "    return predictions,softmax,fc8,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_tensprflow_run(session,target,feed,info_string):\n",
    "    num_step_burn_in =10\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared = 0.0\n",
    "    for i in range(num_batches+num_step_burn_in):\n",
    "        start_time =time.time()\n",
    "        _ = session.run(target,feed_dict=feed)\n",
    "        duration = time.time()-start_time\n",
    "        if i >= num_step_burn_in:\n",
    "            if not i%10:\n",
    "                print('%s: step %d, duration = %.3f' % (datetime.now(),i-num_step_burn_in,duration))\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration * duration\n",
    "    mn = total_duration / num_batches\n",
    "    vr = total_duration_squared / num_batches - mn * mn\n",
    "    sd = math.sqrt(vr)\n",
    "    print('%s: %s across %d step, %.3f +/- %.3f sec/batch' % (datetime.now(),info_string,num_batches,mn,sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-27 20:46:11.774594: step 0, duration = 0.151\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5752525f060f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrun_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5752525f060f>\u001b[0m in \u001b[0;36mrun_benchmark\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtime_tensprflow_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c0d6244983f2>\u001b[0m in \u001b[0;36mtime_tensprflow_run\u001b[0;34m(session, target, feed, info_string)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_step_burn_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_step_burn_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_benchmark():\n",
    "    with tf.Graph().as_default():\n",
    "        image_size = 224\n",
    "        images = tf.Variable(tf.random_normal([batch_size,\n",
    "                                               image_size,\n",
    "                                               image_size,3],\n",
    "                                               dtype=tf.float32,\n",
    "                                               stddev=1e-1))\n",
    "        \n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        predictions,softmax,fc8,p = inference_op(images,keep_prob)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        time_tensprflow_run(sess,predictions,{keep_prob:1.0},\"Forward\")\n",
    "        objective = tf.nn.l2_loss(fc8)\n",
    "        grad = tf.gradients(objective,p)\n",
    "        time_tensprflow_run(sess,grad,{keep_prob:0.5},\"Forward-backward\")\n",
    "\n",
    "batch_size = 32\n",
    "num_batches = 100\n",
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_op(input_op, name, kh, kw, n_out, dh, dw, p):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "    \n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\",shape=[kh, kw, n_in, n_out],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        conv = tf.nn.conv2d(input_op, kernel, (1,dh,dw,1),padding='SAME')\n",
    "        bias_init_val = tf.constant(0.0,shape=[n_out],dtype=tf.float32)\n",
    "        biases = tf.Variable(bias_init_val,trainable=True,name='b')\n",
    "        z = tf.nn.bias_add(conv,biases)\n",
    "        activation = tf.nn.relu(z,name=scope)\n",
    "        p += [kernel, biases]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_op(input_op, name, n_out, p):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "    \n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\",shape=[n_in,n_out],dtype= tf.float32,initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(0.1,shape=[n_out],dtype=tf.float32),name='b')\n",
    "        avtivation = tf.nn.relu_layer(input_op,kernel,biases,name=scope)\n",
    "        p += [kernel,biases]\n",
    "        return avtivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mpool_op(input_op,name, kh,kw,dh,dw):\n",
    "    return tf.nn.max_pool(input_op,ksize=[1,kh,kw,1],strides=[1,dh,dw,1],padding='SAME',name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_op(input_op,keep_prob):\n",
    "    p = []\n",
    "    conv1_1 = conv_op(input_op,name=\"conv1_1\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
    "    conv1_2 = conv_op(conv1_1,name=\"conv1_2\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
    "    pool1 = mpool_op(conv1_2,name=\"pool1\",kh=2,kw=2,dw=2,dh=2)\n",
    "    \n",
    "    conv2_1 = conv_op(pool1,name=\"conv2_1\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
    "    conv2_2 = conv_op(conv2_1,name=\"conv2_2\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
    "    pool2 = mpool_op(conv2_2,name=\"pool2\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    conv3_1 = conv_op(pool2,name=\"conv3_1\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    conv3_2 = conv_op(conv3_1,name=\"conv3_2\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    conv3_3 = conv_op(conv3_2,name=\"conv3_3\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
    "    pool3 = mpool_op(conv3_3,name=\"pool3\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    conv4_1 = conv_op(pool3,name=\"conv4_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv4_2 = conv_op(conv4_1,name=\"conv4_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv4_3 = conv_op(conv4_2,name=\"conv4_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    pool4 = mpool_op(conv4_3,name=\"pool4\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    conv5_1 = conv_op(pool4,name=\"conv5_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv5_2 = conv_op(conv5_1,name=\"conv5_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    conv5_3 = conv_op(conv5_2,name=\"conv5_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
    "    pool5 = mpool_op(conv5_3,name=\"pool5\",kh=2,kw=2,dh=2,dw=2)\n",
    "    \n",
    "    shp = pool5.get_shape()\n",
    "    flattened_shape = shp[1].value * shp[2].value * shp[3].value\n",
    "    resh1 = tf.reshape(pool5,[-1,flattened_shape],name=\"resh1\")\n",
    "    \n",
    "    fc6 = fc_op(resh1,name=\"fc6\",n_out=4096,p=p)\n",
    "    fc6_drop = tf.nn.dropout(fc6,keep_prob,name=\"fc6_drop\")\n",
    "    \n",
    "    fc7 = fc_op(fc6_drop,name=\"fc7\",n_out=4096,p=p)\n",
    "    fc7_drop = tf.nn.dropout(fc7,keep_prob,name=\"fc7_drop\")\n",
    "    \n",
    "    fc8 = fc_op(fc7_drop,name=\"fc8\",n_out=1000,p=p)\n",
    "    softmax=tf.nn.softmax(fc8)\n",
    "    predictions = tf.argmax(softmax,1)\n",
    "    return predictions,softmax,fc8,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_tensprflow_run(session,target,feed,info_string):\n",
    "    num_step_burn_in =10\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared = 0.0\n",
    "    for i in range(num_batches+num_step_burn_in):\n",
    "        start_time =time.time()\n",
    "        _ = session.run(target,feed_dict=feed)\n",
    "        duration = time.time()-start_time\n",
    "        if i >= num_step_burn_in:\n",
    "            if not i%10:\n",
    "                print('%s: step %d, duration = %.3f' % (datetime.now(),i-num_step_burn_in,duration))\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration * duration\n",
    "    mn = total_duration / num_batches\n",
    "    vr = total_duration_squared / num_batches - mn * mn\n",
    "    sd = math.sqrt(vr)\n",
    "    print('%s: %s across %d step, %.3f +/- %.3f sec/batch' % (datetime.now(),info_string,num_batches,mn,sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    with tf.Graph().as_default():\n",
    "        image_size = 224\n",
    "        images = tf.Variable(tf.random_normal([batch_size,\n",
    "                                               image_size,\n",
    "                                               image_size,3],\n",
    "                                               dtype=tf.float32,\n",
    "                                               stddev=1e-1))\n",
    "        \n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        predictions,softmax,fc8,p = inference_op(images,keep_prob)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        time_tensprflow_run(sess,predictions,{keep_prob:1.0},\"Forward\")\n",
    "        objective = tf.nn.l2_loss(fc8)\n",
    "        grad = tf.gradients(objective,p)\n",
    "        time_tensprflow_run(sess,grad,{keep_prob:0.5},\"Forward-backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_batches = 100\n",
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
