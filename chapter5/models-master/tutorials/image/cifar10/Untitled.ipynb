{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cifar10,cifar10_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_steps = 3000\n",
    "batch_size = 128\n",
    "data_dir = '/tmp/cifar10_data/cifar-10-batches-bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_with_weight_loss(shape,stddev,wl):\n",
    "    var = tf.Variable(tf.truncated_normal(shape,stddev = stddev))\n",
    "    if wl is not None:\n",
    "        weight_loss = tf.multiply(tf.nn.l2_loss(var),wl,name='weight_loss')\n",
    "        tf.add_to_collection('losses',weight_loss)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/tmp/cifar10_data/cifar-10-batches-bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ddaee26bfd14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_download_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wjj/TFbook/chapter5/models-master/tutorials/image/cifar10/cifar10.py\u001b[0m in \u001b[0;36mmaybe_download_and_extract\u001b[0;34m()\u001b[0m\n\u001b[1;32m    397\u001b[0m   \u001b[0mextracted_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cifar-10-batches-bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0;32m-> 2003\u001b[0;31m                          numeric_owner=numeric_owner)\n\u001b[0m\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0;31m# Reverse sort directories.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2043\u001b[0m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[1;32m   2044\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                                  numeric_owner=numeric_owner)\n\u001b[0m\u001b[1;32m   2046\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfifo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefifo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mmakedir\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2144\u001b[0m             \u001b[0;31m# Use a safe mode for the directory, the real mode is set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m             \u001b[0;31m# later in _extract_member().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0o700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/tmp/cifar10_data/cifar-10-batches-bin'"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "images_train,labels_train = cifar10_input.distorted_inputs(data_dir=data_dir,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_test,labels_test = cifar10_input.inputs(eval_data=True, data_dir=data_dir,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_holder = tf.placeholder(tf.float32,[batch_size,24,24,3])\n",
    "\n",
    "label_holder = tf.placeholder(tf.int32, [batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight1 = variable_with_weight_loss(shape=[5,5,3,64],stddev=53-2,wl=0.0)\n",
    "kernel1 = tf.nn.conv2d(image_holder,weight1,[1,1,1,1],padding='SAME')\n",
    "bias1 = tf.Variable(tf.constant(0.0,shape=[64]))\n",
    "conv1 = tf.nn.relu(tf.nn.bias_add(kernel1,bias1))\n",
    "pool1 = tf.nn.max_pool(conv1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')\n",
    "norm1 = tf.nn.lrn(pool1,4,bias=1.0,alpha=0.001/9.0,beta=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight2 = variable_with_weight_loss(shape=[5,5,64,64],stddev=5e-2,wl=0.0)\n",
    "kernel2 = tf.nn.conv2d(norm1,weight2,[1,1,1,1],padding='SAME')\n",
    "bias2 = tf.Variable(tf.constant(0.1,shape=[64]))\n",
    "conv2 = tf.nn.relu(tf.nn.bias_add(kernel2,bias2))\n",
    "norm2 = tf.nn.lrn(conv2,4,bias=1.0,alpha=0.001/9.0,beta=0.75)\n",
    "pool2 = tf.nn.max_pool(norm2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reshape = tf.reshape(pool2,[batch_size,-1])\n",
    "dim = reshape.get_shape()[1].value\n",
    "weight3 = variable_with_weight_loss(shape=[dim,384],stddev=0.04,wl=0.004)\n",
    "bias3 = tf.Variable(tf.constant(0.1,shape=[384]))\n",
    "local3 = tf.nn.relu(tf.matmul(reshape,weight3)+bias3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight4 = variable_with_weight_loss(shape=[384,192],stddev=0.04,wl=0.04)\n",
    "bias4 = tf.Variable(tf.constant(0.1,shape=[192]))\n",
    "local4 = tf.nn.relu(tf.matmul(local3,weight4)+bias4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight5 = variable_with_weight_loss(shape=[192,10],stddev=0.04,wl=0.04)\n",
    "bias5 = tf.Variable(tf.constant(0.0,shape=[10]))\n",
    "logits = tf.add(tf.matmul(local4,weight5),bias5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits,labels):\n",
    "    labels = tf.cast(labels,tf.int64)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=labels,name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy,name='cross_entropy')\n",
    "    tf.add_to_collection('losses',cross_entropy_mean)\n",
    "    return tf.add_n(tf.get_collection('losses'),name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = loss(logits,label_holder)\n",
    "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_k_op = tf.nn.in_top_k(logits,label_holder,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-4, started daemon 140681100121856)>,\n",
       " <Thread(Thread-5, started daemon 140681091729152)>,\n",
       " <Thread(Thread-6, started daemon 140681083336448)>,\n",
       " <Thread(Thread-7, started daemon 140681074943744)>,\n",
       " <Thread(Thread-8, started daemon 140681066551040)>,\n",
       " <Thread(Thread-9, started daemon 140680110274304)>,\n",
       " <Thread(Thread-10, started daemon 140680101881600)>,\n",
       " <Thread(Thread-11, started daemon 140680093488896)>,\n",
       " <Thread(Thread-12, started daemon 140680085096192)>,\n",
       " <Thread(Thread-13, started daemon 140680076703488)>,\n",
       " <Thread(Thread-14, started daemon 140680068310784)>,\n",
       " <Thread(Thread-15, started daemon 140680059918080)>,\n",
       " <Thread(Thread-16, started daemon 140679573403392)>,\n",
       " <Thread(Thread-17, started daemon 140679565010688)>,\n",
       " <Thread(Thread-18, started daemon 140679556617984)>,\n",
       " <Thread(Thread-19, started daemon 140679548225280)>,\n",
       " <Thread(Thread-20, started daemon 140679539832576)>,\n",
       " <Thread(Thread-21, started daemon 140679531439872)>,\n",
       " <Thread(Thread-22, started daemon 140679523047168)>,\n",
       " <Thread(Thread-23, started daemon 140679036532480)>,\n",
       " <Thread(Thread-24, started daemon 140679028139776)>,\n",
       " <Thread(Thread-25, started daemon 140679019747072)>,\n",
       " <Thread(Thread-26, started daemon 140679011354368)>,\n",
       " <Thread(Thread-27, started daemon 140679002961664)>,\n",
       " <Thread(Thread-28, started daemon 140678994568960)>,\n",
       " <Thread(Thread-29, started daemon 140678986176256)>,\n",
       " <Thread(Thread-30, started daemon 140678499661568)>,\n",
       " <Thread(Thread-31, started daemon 140678491268864)>,\n",
       " <Thread(Thread-32, started daemon 140678482876160)>,\n",
       " <Thread(Thread-33, started daemon 140678474483456)>,\n",
       " <Thread(Thread-34, started daemon 140678466090752)>,\n",
       " <Thread(Thread-35, started daemon 140678457698048)>,\n",
       " <Thread(Thread-36, started daemon 140678449305344)>,\n",
       " <Thread(Thread-37, started daemon 140677962790656)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.start_queue_runners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0,loss9.63(15.5 examples/sec; 8.277 sec/batch)\n",
      "step 10,loss5.99(2200.9 examples/sec; 0.058 sec/batch)\n",
      "step 20,loss5.62(2489.7 examples/sec; 0.051 sec/batch)\n",
      "step 30,loss5.18(2489.3 examples/sec; 0.051 sec/batch)\n",
      "step 40,loss4.89(2564.3 examples/sec; 0.050 sec/batch)\n",
      "step 50,loss4.84(2284.5 examples/sec; 0.056 sec/batch)\n",
      "step 60,loss4.64(1757.0 examples/sec; 0.073 sec/batch)\n",
      "step 70,loss4.50(2351.0 examples/sec; 0.054 sec/batch)\n",
      "step 80,loss4.34(2431.9 examples/sec; 0.053 sec/batch)\n",
      "step 90,loss4.16(2482.4 examples/sec; 0.052 sec/batch)\n",
      "step 100,loss4.11(2583.6 examples/sec; 0.050 sec/batch)\n",
      "step 110,loss4.02(1316.3 examples/sec; 0.097 sec/batch)\n",
      "step 120,loss3.88(2493.5 examples/sec; 0.051 sec/batch)\n",
      "step 130,loss3.79(1689.0 examples/sec; 0.076 sec/batch)\n",
      "step 140,loss3.61(2557.8 examples/sec; 0.050 sec/batch)\n",
      "step 150,loss3.70(2344.3 examples/sec; 0.055 sec/batch)\n",
      "step 160,loss3.69(847.0 examples/sec; 0.151 sec/batch)\n",
      "step 170,loss3.67(2499.3 examples/sec; 0.051 sec/batch)\n",
      "step 180,loss3.51(2553.5 examples/sec; 0.050 sec/batch)\n",
      "step 190,loss3.45(2570.4 examples/sec; 0.050 sec/batch)\n",
      "step 200,loss3.61(2453.1 examples/sec; 0.052 sec/batch)\n",
      "step 210,loss3.53(2394.6 examples/sec; 0.053 sec/batch)\n",
      "step 220,loss3.39(2397.5 examples/sec; 0.053 sec/batch)\n",
      "step 230,loss3.33(1415.3 examples/sec; 0.090 sec/batch)\n",
      "step 240,loss3.16(2342.8 examples/sec; 0.055 sec/batch)\n",
      "step 250,loss3.23(2414.4 examples/sec; 0.053 sec/batch)\n",
      "step 260,loss3.17(2413.0 examples/sec; 0.053 sec/batch)\n",
      "step 270,loss3.14(2390.1 examples/sec; 0.054 sec/batch)\n",
      "step 280,loss2.97(1523.8 examples/sec; 0.084 sec/batch)\n",
      "step 290,loss3.03(2469.1 examples/sec; 0.052 sec/batch)\n",
      "step 300,loss2.90(2549.5 examples/sec; 0.050 sec/batch)\n",
      "step 310,loss2.90(2468.6 examples/sec; 0.052 sec/batch)\n",
      "step 320,loss2.85(2456.9 examples/sec; 0.052 sec/batch)\n",
      "step 330,loss2.92(1568.8 examples/sec; 0.082 sec/batch)\n",
      "step 340,loss2.89(2356.7 examples/sec; 0.054 sec/batch)\n",
      "step 350,loss2.75(2338.1 examples/sec; 0.055 sec/batch)\n",
      "step 360,loss2.73(2339.6 examples/sec; 0.055 sec/batch)\n",
      "step 370,loss2.81(2507.8 examples/sec; 0.051 sec/batch)\n",
      "step 380,loss2.78(2373.4 examples/sec; 0.054 sec/batch)\n",
      "step 390,loss2.83(2473.1 examples/sec; 0.052 sec/batch)\n",
      "step 400,loss2.72(1271.4 examples/sec; 0.101 sec/batch)\n",
      "step 410,loss2.79(2414.0 examples/sec; 0.053 sec/batch)\n",
      "step 420,loss2.60(2463.6 examples/sec; 0.052 sec/batch)\n",
      "step 430,loss2.74(2474.5 examples/sec; 0.052 sec/batch)\n",
      "step 440,loss2.61(2485.2 examples/sec; 0.052 sec/batch)\n",
      "step 450,loss2.58(1108.3 examples/sec; 0.115 sec/batch)\n",
      "step 460,loss2.60(2540.7 examples/sec; 0.050 sec/batch)\n",
      "step 470,loss2.47(2428.5 examples/sec; 0.053 sec/batch)\n",
      "step 480,loss2.57(2530.6 examples/sec; 0.051 sec/batch)\n",
      "step 490,loss2.50(2399.2 examples/sec; 0.053 sec/batch)\n",
      "step 500,loss2.52(2345.5 examples/sec; 0.055 sec/batch)\n",
      "step 510,loss2.55(2425.2 examples/sec; 0.053 sec/batch)\n",
      "step 520,loss2.49(2010.2 examples/sec; 0.064 sec/batch)\n",
      "step 530,loss2.35(2432.9 examples/sec; 0.053 sec/batch)\n",
      "step 540,loss2.42(2360.1 examples/sec; 0.054 sec/batch)\n",
      "step 550,loss2.32(2489.1 examples/sec; 0.051 sec/batch)\n",
      "step 560,loss2.48(2486.0 examples/sec; 0.051 sec/batch)\n",
      "step 570,loss2.43(2518.5 examples/sec; 0.051 sec/batch)\n",
      "step 580,loss2.40(2540.6 examples/sec; 0.050 sec/batch)\n",
      "step 590,loss2.31(2505.1 examples/sec; 0.051 sec/batch)\n",
      "step 600,loss2.36(2415.5 examples/sec; 0.053 sec/batch)\n",
      "step 610,loss2.26(2372.4 examples/sec; 0.054 sec/batch)\n",
      "step 620,loss2.42(1814.4 examples/sec; 0.071 sec/batch)\n",
      "step 630,loss2.22(2505.0 examples/sec; 0.051 sec/batch)\n",
      "step 640,loss2.39(2434.8 examples/sec; 0.053 sec/batch)\n",
      "step 650,loss2.31(2662.2 examples/sec; 0.048 sec/batch)\n",
      "step 660,loss2.34(2480.8 examples/sec; 0.052 sec/batch)\n",
      "step 670,loss2.26(1975.7 examples/sec; 0.065 sec/batch)\n",
      "step 680,loss2.16(2468.1 examples/sec; 0.052 sec/batch)\n",
      "step 690,loss2.19(2438.6 examples/sec; 0.052 sec/batch)\n",
      "step 700,loss2.30(2581.7 examples/sec; 0.050 sec/batch)\n",
      "step 710,loss2.29(2520.8 examples/sec; 0.051 sec/batch)\n",
      "step 720,loss2.17(727.4 examples/sec; 0.176 sec/batch)\n",
      "step 730,loss2.20(2435.5 examples/sec; 0.053 sec/batch)\n",
      "step 740,loss2.10(2431.2 examples/sec; 0.053 sec/batch)\n",
      "step 750,loss2.01(2528.3 examples/sec; 0.051 sec/batch)\n",
      "step 760,loss2.07(2063.0 examples/sec; 0.062 sec/batch)\n",
      "step 770,loss2.04(1243.8 examples/sec; 0.103 sec/batch)\n",
      "step 780,loss2.08(2482.6 examples/sec; 0.052 sec/batch)\n",
      "step 790,loss2.10(2444.2 examples/sec; 0.052 sec/batch)\n",
      "step 800,loss2.09(2509.3 examples/sec; 0.051 sec/batch)\n",
      "step 810,loss2.02(2413.9 examples/sec; 0.053 sec/batch)\n",
      "step 820,loss2.00(2538.0 examples/sec; 0.050 sec/batch)\n",
      "step 830,loss2.01(2404.9 examples/sec; 0.053 sec/batch)\n",
      "step 840,loss1.98(2111.9 examples/sec; 0.061 sec/batch)\n",
      "step 850,loss2.16(2456.5 examples/sec; 0.052 sec/batch)\n",
      "step 860,loss1.95(2583.3 examples/sec; 0.050 sec/batch)\n",
      "step 870,loss1.96(2479.7 examples/sec; 0.052 sec/batch)\n",
      "step 880,loss2.14(2481.0 examples/sec; 0.052 sec/batch)\n",
      "step 890,loss2.00(2073.6 examples/sec; 0.062 sec/batch)\n",
      "step 900,loss1.88(2567.1 examples/sec; 0.050 sec/batch)\n",
      "step 910,loss1.92(2457.0 examples/sec; 0.052 sec/batch)\n",
      "step 920,loss2.05(2333.3 examples/sec; 0.055 sec/batch)\n",
      "step 930,loss1.85(2498.5 examples/sec; 0.051 sec/batch)\n",
      "step 940,loss2.06(2107.1 examples/sec; 0.061 sec/batch)\n",
      "step 950,loss1.86(2534.9 examples/sec; 0.050 sec/batch)\n",
      "step 960,loss1.90(2423.3 examples/sec; 0.053 sec/batch)\n",
      "step 970,loss1.98(2485.9 examples/sec; 0.051 sec/batch)\n",
      "step 980,loss1.94(2490.4 examples/sec; 0.051 sec/batch)\n",
      "step 990,loss1.92(1861.2 examples/sec; 0.069 sec/batch)\n",
      "step 1000,loss2.07(2606.7 examples/sec; 0.049 sec/batch)\n",
      "step 1010,loss1.97(2346.1 examples/sec; 0.055 sec/batch)\n",
      "step 1020,loss2.01(2474.3 examples/sec; 0.052 sec/batch)\n",
      "step 1030,loss1.80(2453.3 examples/sec; 0.052 sec/batch)\n",
      "step 1040,loss1.92(2071.8 examples/sec; 0.062 sec/batch)\n",
      "step 1050,loss1.96(2473.6 examples/sec; 0.052 sec/batch)\n",
      "step 1060,loss2.07(2481.8 examples/sec; 0.052 sec/batch)\n",
      "step 1070,loss2.01(2412.1 examples/sec; 0.053 sec/batch)\n",
      "step 1080,loss1.83(2482.2 examples/sec; 0.052 sec/batch)\n",
      "step 1090,loss2.04(1981.4 examples/sec; 0.065 sec/batch)\n",
      "step 1100,loss1.74(2386.2 examples/sec; 0.054 sec/batch)\n",
      "step 1110,loss1.96(2484.0 examples/sec; 0.052 sec/batch)\n",
      "step 1120,loss1.83(2416.2 examples/sec; 0.053 sec/batch)\n",
      "step 1130,loss1.83(2305.8 examples/sec; 0.056 sec/batch)\n",
      "step 1140,loss1.83(797.5 examples/sec; 0.161 sec/batch)\n",
      "step 1150,loss1.88(2410.4 examples/sec; 0.053 sec/batch)\n",
      "step 1160,loss1.71(2459.8 examples/sec; 0.052 sec/batch)\n",
      "step 1170,loss1.77(2296.9 examples/sec; 0.056 sec/batch)\n",
      "step 1180,loss1.90(2098.3 examples/sec; 0.061 sec/batch)\n",
      "step 1190,loss1.92(1433.6 examples/sec; 0.089 sec/batch)\n",
      "step 1200,loss1.83(2647.5 examples/sec; 0.048 sec/batch)\n",
      "step 1210,loss1.82(2333.8 examples/sec; 0.055 sec/batch)\n",
      "step 1220,loss1.83(2552.6 examples/sec; 0.050 sec/batch)\n",
      "step 1230,loss1.75(2522.4 examples/sec; 0.051 sec/batch)\n",
      "step 1240,loss1.83(1185.3 examples/sec; 0.108 sec/batch)\n",
      "step 1250,loss1.71(2553.8 examples/sec; 0.050 sec/batch)\n",
      "step 1260,loss1.79(2420.9 examples/sec; 0.053 sec/batch)\n",
      "step 1270,loss1.82(2441.6 examples/sec; 0.052 sec/batch)\n",
      "step 1280,loss1.82(2589.8 examples/sec; 0.049 sec/batch)\n",
      "step 1290,loss1.55(2422.9 examples/sec; 0.053 sec/batch)\n",
      "step 1300,loss1.63(2394.5 examples/sec; 0.053 sec/batch)\n",
      "step 1310,loss1.80(2178.2 examples/sec; 0.059 sec/batch)\n",
      "step 1320,loss1.71(2425.9 examples/sec; 0.053 sec/batch)\n",
      "step 1330,loss1.81(2516.1 examples/sec; 0.051 sec/batch)\n",
      "step 1340,loss1.69(2533.4 examples/sec; 0.051 sec/batch)\n",
      "step 1350,loss1.66(2388.6 examples/sec; 0.054 sec/batch)\n",
      "step 1360,loss1.72(1629.2 examples/sec; 0.079 sec/batch)\n",
      "step 1370,loss1.78(2516.5 examples/sec; 0.051 sec/batch)\n",
      "step 1380,loss1.70(2378.4 examples/sec; 0.054 sec/batch)\n",
      "step 1390,loss1.73(2341.3 examples/sec; 0.055 sec/batch)\n",
      "step 1400,loss1.69(2467.4 examples/sec; 0.052 sec/batch)\n",
      "step 1410,loss1.75(1758.3 examples/sec; 0.073 sec/batch)\n",
      "step 1420,loss1.73(2458.7 examples/sec; 0.052 sec/batch)\n",
      "step 1430,loss1.57(2048.2 examples/sec; 0.062 sec/batch)\n",
      "step 1440,loss1.74(2462.0 examples/sec; 0.052 sec/batch)\n",
      "step 1450,loss1.74(2554.5 examples/sec; 0.050 sec/batch)\n",
      "step 1460,loss1.67(2550.2 examples/sec; 0.050 sec/batch)\n",
      "step 1470,loss1.65(2461.4 examples/sec; 0.052 sec/batch)\n",
      "step 1480,loss1.85(1839.0 examples/sec; 0.070 sec/batch)\n",
      "step 1490,loss1.64(2447.0 examples/sec; 0.052 sec/batch)\n",
      "step 1500,loss1.69(2417.1 examples/sec; 0.053 sec/batch)\n",
      "step 1510,loss1.62(2520.2 examples/sec; 0.051 sec/batch)\n",
      "step 1520,loss1.82(2234.9 examples/sec; 0.057 sec/batch)\n",
      "step 1530,loss1.77(931.3 examples/sec; 0.137 sec/batch)\n",
      "step 1540,loss1.64(2463.1 examples/sec; 0.052 sec/batch)\n",
      "step 1550,loss1.68(2630.3 examples/sec; 0.049 sec/batch)\n",
      "step 1560,loss1.64(2588.3 examples/sec; 0.049 sec/batch)\n",
      "step 1570,loss1.70(2611.5 examples/sec; 0.049 sec/batch)\n",
      "step 1580,loss1.80(1240.2 examples/sec; 0.103 sec/batch)\n",
      "step 1590,loss1.68(2461.2 examples/sec; 0.052 sec/batch)\n",
      "step 1600,loss1.70(2470.7 examples/sec; 0.052 sec/batch)\n",
      "step 1610,loss1.67(2415.5 examples/sec; 0.053 sec/batch)\n",
      "step 1620,loss1.77(2409.6 examples/sec; 0.053 sec/batch)\n",
      "step 1630,loss1.62(2362.3 examples/sec; 0.054 sec/batch)\n",
      "step 1640,loss1.47(2477.3 examples/sec; 0.052 sec/batch)\n",
      "step 1650,loss1.57(1827.6 examples/sec; 0.070 sec/batch)\n",
      "step 1660,loss1.78(2401.3 examples/sec; 0.053 sec/batch)\n",
      "step 1670,loss1.56(2409.0 examples/sec; 0.053 sec/batch)\n",
      "step 1680,loss1.72(2403.2 examples/sec; 0.053 sec/batch)\n",
      "step 1690,loss1.68(2242.0 examples/sec; 0.057 sec/batch)\n",
      "step 1700,loss1.64(1716.2 examples/sec; 0.075 sec/batch)\n",
      "step 1710,loss1.74(2402.1 examples/sec; 0.053 sec/batch)\n",
      "step 1720,loss1.72(2407.6 examples/sec; 0.053 sec/batch)\n",
      "step 1730,loss1.72(2427.6 examples/sec; 0.053 sec/batch)\n",
      "step 1740,loss1.73(2443.3 examples/sec; 0.052 sec/batch)\n",
      "step 1750,loss1.61(1010.6 examples/sec; 0.127 sec/batch)\n",
      "step 1760,loss1.59(2433.5 examples/sec; 0.053 sec/batch)\n",
      "step 1770,loss1.48(2449.1 examples/sec; 0.052 sec/batch)\n",
      "step 1780,loss1.51(2642.2 examples/sec; 0.048 sec/batch)\n",
      "step 1790,loss1.50(2516.3 examples/sec; 0.051 sec/batch)\n",
      "step 1800,loss1.58(2156.6 examples/sec; 0.059 sec/batch)\n",
      "step 1810,loss1.66(2486.3 examples/sec; 0.051 sec/batch)\n",
      "step 1820,loss1.54(2435.0 examples/sec; 0.053 sec/batch)\n",
      "step 1830,loss1.48(2497.4 examples/sec; 0.051 sec/batch)\n",
      "step 1840,loss1.65(2528.4 examples/sec; 0.051 sec/batch)\n",
      "step 1850,loss1.61(2557.4 examples/sec; 0.050 sec/batch)\n",
      "step 1860,loss1.56(2461.9 examples/sec; 0.052 sec/batch)\n",
      "step 1870,loss1.52(2146.1 examples/sec; 0.060 sec/batch)\n",
      "step 1880,loss1.52(2384.9 examples/sec; 0.054 sec/batch)\n",
      "step 1890,loss1.54(2491.4 examples/sec; 0.051 sec/batch)\n",
      "step 1900,loss1.68(2451.0 examples/sec; 0.052 sec/batch)\n",
      "step 1910,loss1.53(2436.8 examples/sec; 0.053 sec/batch)\n",
      "step 1920,loss1.67(1819.5 examples/sec; 0.070 sec/batch)\n",
      "step 1930,loss1.75(2369.3 examples/sec; 0.054 sec/batch)\n",
      "step 1940,loss1.64(2560.9 examples/sec; 0.050 sec/batch)\n",
      "step 1950,loss1.59(2447.0 examples/sec; 0.052 sec/batch)\n",
      "step 1960,loss1.60(2457.6 examples/sec; 0.052 sec/batch)\n",
      "step 1970,loss1.56(1152.5 examples/sec; 0.111 sec/batch)\n",
      "step 1980,loss1.63(2479.6 examples/sec; 0.052 sec/batch)\n",
      "step 1990,loss1.56(2367.6 examples/sec; 0.054 sec/batch)\n",
      "step 2000,loss1.64(2594.2 examples/sec; 0.049 sec/batch)\n",
      "step 2010,loss1.56(2411.6 examples/sec; 0.053 sec/batch)\n",
      "step 2020,loss1.56(2383.7 examples/sec; 0.054 sec/batch)\n",
      "step 2030,loss1.60(2421.3 examples/sec; 0.053 sec/batch)\n",
      "step 2040,loss1.51(2406.0 examples/sec; 0.053 sec/batch)\n",
      "step 2050,loss1.83(2370.3 examples/sec; 0.054 sec/batch)\n",
      "step 2060,loss1.54(2589.9 examples/sec; 0.049 sec/batch)\n",
      "step 2070,loss1.70(2382.2 examples/sec; 0.054 sec/batch)\n",
      "step 2080,loss1.56(2467.3 examples/sec; 0.052 sec/batch)\n",
      "step 2090,loss1.78(1740.5 examples/sec; 0.074 sec/batch)\n",
      "step 2100,loss1.63(2543.4 examples/sec; 0.050 sec/batch)\n",
      "step 2110,loss1.52(2535.1 examples/sec; 0.050 sec/batch)\n",
      "step 2120,loss1.64(2369.1 examples/sec; 0.054 sec/batch)\n",
      "step 2130,loss1.58(2520.5 examples/sec; 0.051 sec/batch)\n",
      "step 2140,loss1.68(1989.7 examples/sec; 0.064 sec/batch)\n",
      "step 2150,loss1.65(2404.0 examples/sec; 0.053 sec/batch)\n",
      "step 2160,loss1.65(1984.3 examples/sec; 0.065 sec/batch)\n",
      "step 2170,loss1.63(2441.0 examples/sec; 0.052 sec/batch)\n",
      "step 2180,loss1.63(2545.6 examples/sec; 0.050 sec/batch)\n",
      "step 2190,loss1.50(2292.8 examples/sec; 0.056 sec/batch)\n",
      "step 2200,loss1.52(2732.0 examples/sec; 0.047 sec/batch)\n",
      "step 2210,loss1.60(2404.4 examples/sec; 0.053 sec/batch)\n",
      "step 2220,loss1.57(2203.4 examples/sec; 0.058 sec/batch)\n",
      "step 2230,loss1.73(2573.6 examples/sec; 0.050 sec/batch)\n",
      "step 2240,loss1.59(2450.1 examples/sec; 0.052 sec/batch)\n",
      "step 2250,loss1.59(2565.3 examples/sec; 0.050 sec/batch)\n",
      "step 2260,loss1.63(2512.5 examples/sec; 0.051 sec/batch)\n",
      "step 2270,loss1.80(2447.6 examples/sec; 0.052 sec/batch)\n",
      "step 2280,loss1.37(2497.6 examples/sec; 0.051 sec/batch)\n",
      "step 2290,loss1.44(1956.5 examples/sec; 0.065 sec/batch)\n",
      "step 2300,loss1.53(2359.4 examples/sec; 0.054 sec/batch)\n",
      "step 2310,loss1.45(2437.5 examples/sec; 0.053 sec/batch)\n",
      "step 2320,loss1.59(2443.9 examples/sec; 0.052 sec/batch)\n",
      "step 2330,loss1.64(2473.8 examples/sec; 0.052 sec/batch)\n",
      "step 2340,loss1.82(1809.6 examples/sec; 0.071 sec/batch)\n",
      "step 2350,loss1.57(2517.8 examples/sec; 0.051 sec/batch)\n",
      "step 2360,loss1.59(2536.2 examples/sec; 0.050 sec/batch)\n",
      "step 2370,loss1.46(2529.4 examples/sec; 0.051 sec/batch)\n",
      "step 2380,loss1.60(2308.0 examples/sec; 0.055 sec/batch)\n",
      "step 2390,loss1.63(1630.2 examples/sec; 0.079 sec/batch)\n",
      "step 2400,loss1.56(2457.1 examples/sec; 0.052 sec/batch)\n",
      "step 2410,loss1.53(2488.0 examples/sec; 0.051 sec/batch)\n",
      "step 2420,loss1.47(2503.9 examples/sec; 0.051 sec/batch)\n",
      "step 2430,loss1.65(2565.7 examples/sec; 0.050 sec/batch)\n",
      "step 2440,loss1.58(1121.7 examples/sec; 0.114 sec/batch)\n",
      "step 2450,loss1.47(2429.9 examples/sec; 0.053 sec/batch)\n",
      "step 2460,loss1.53(2558.5 examples/sec; 0.050 sec/batch)\n",
      "step 2470,loss1.40(2516.8 examples/sec; 0.051 sec/batch)\n",
      "step 2480,loss1.55(2421.8 examples/sec; 0.053 sec/batch)\n",
      "step 2490,loss1.51(2546.1 examples/sec; 0.050 sec/batch)\n",
      "step 2500,loss1.62(2426.9 examples/sec; 0.053 sec/batch)\n",
      "step 2510,loss1.53(2362.1 examples/sec; 0.054 sec/batch)\n",
      "step 2520,loss1.64(2498.0 examples/sec; 0.051 sec/batch)\n",
      "step 2530,loss1.48(2536.4 examples/sec; 0.050 sec/batch)\n",
      "step 2540,loss1.55(983.4 examples/sec; 0.130 sec/batch)\n",
      "step 2550,loss1.59(2459.6 examples/sec; 0.052 sec/batch)\n",
      "step 2560,loss1.58(2614.9 examples/sec; 0.049 sec/batch)\n",
      "step 2570,loss1.40(2429.8 examples/sec; 0.053 sec/batch)\n",
      "step 2580,loss1.53(2543.6 examples/sec; 0.050 sec/batch)\n",
      "step 2590,loss1.58(1361.0 examples/sec; 0.094 sec/batch)\n",
      "step 2600,loss1.66(2394.3 examples/sec; 0.053 sec/batch)\n",
      "step 2610,loss1.50(2147.7 examples/sec; 0.060 sec/batch)\n",
      "step 2620,loss1.57(2526.4 examples/sec; 0.051 sec/batch)\n",
      "step 2630,loss1.53(2399.4 examples/sec; 0.053 sec/batch)\n",
      "step 2640,loss1.51(2467.2 examples/sec; 0.052 sec/batch)\n",
      "step 2650,loss1.60(2373.9 examples/sec; 0.054 sec/batch)\n",
      "step 2660,loss1.49(1424.0 examples/sec; 0.090 sec/batch)\n",
      "step 2670,loss1.59(2408.7 examples/sec; 0.053 sec/batch)\n",
      "step 2680,loss1.52(2594.0 examples/sec; 0.049 sec/batch)\n",
      "step 2690,loss1.50(2394.8 examples/sec; 0.053 sec/batch)\n",
      "step 2700,loss1.61(2207.8 examples/sec; 0.058 sec/batch)\n",
      "step 2710,loss1.52(1492.9 examples/sec; 0.086 sec/batch)\n",
      "step 2720,loss1.59(2412.9 examples/sec; 0.053 sec/batch)\n",
      "step 2730,loss1.54(2452.3 examples/sec; 0.052 sec/batch)\n",
      "step 2740,loss1.60(2518.7 examples/sec; 0.051 sec/batch)\n",
      "step 2750,loss1.63(2284.8 examples/sec; 0.056 sec/batch)\n",
      "step 2760,loss1.44(1665.9 examples/sec; 0.077 sec/batch)\n",
      "step 2770,loss1.57(2506.1 examples/sec; 0.051 sec/batch)\n",
      "step 2780,loss1.44(2464.1 examples/sec; 0.052 sec/batch)\n",
      "step 2790,loss1.55(2580.4 examples/sec; 0.050 sec/batch)\n",
      "step 2800,loss1.39(2498.5 examples/sec; 0.051 sec/batch)\n",
      "step 2810,loss1.52(2521.3 examples/sec; 0.051 sec/batch)\n",
      "step 2820,loss1.69(2450.6 examples/sec; 0.052 sec/batch)\n",
      "step 2830,loss1.48(2411.7 examples/sec; 0.053 sec/batch)\n",
      "step 2840,loss1.29(2493.8 examples/sec; 0.051 sec/batch)\n",
      "step 2850,loss1.64(2442.8 examples/sec; 0.052 sec/batch)\n",
      "step 2860,loss1.64(1503.7 examples/sec; 0.085 sec/batch)\n",
      "step 2870,loss1.56(2554.2 examples/sec; 0.050 sec/batch)\n",
      "step 2880,loss1.57(2526.0 examples/sec; 0.051 sec/batch)\n",
      "step 2890,loss1.38(2378.1 examples/sec; 0.054 sec/batch)\n",
      "step 2900,loss1.45(2538.9 examples/sec; 0.050 sec/batch)\n",
      "step 2910,loss1.51(2400.8 examples/sec; 0.053 sec/batch)\n",
      "step 2920,loss1.48(2351.3 examples/sec; 0.054 sec/batch)\n",
      "step 2930,loss1.40(2010.4 examples/sec; 0.064 sec/batch)\n",
      "step 2940,loss1.43(2432.9 examples/sec; 0.053 sec/batch)\n",
      "step 2950,loss1.52(2453.2 examples/sec; 0.052 sec/batch)\n",
      "step 2960,loss1.36(2467.6 examples/sec; 0.052 sec/batch)\n",
      "step 2970,loss1.67(2510.7 examples/sec; 0.051 sec/batch)\n",
      "step 2980,loss1.39(1155.1 examples/sec; 0.111 sec/batch)\n",
      "step 2990,loss1.52(2515.8 examples/sec; 0.051 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "for step in range(max_steps):\n",
    "    start_time = time.time()\n",
    "    image_batch,label_batch = sess.run([images_train,labels_train])\n",
    "    _,loss_value = sess.run([train_op,loss],feed_dict={image_holder:image_batch,label_holder:label_batch})\n",
    "    duration = time.time() - start_time\n",
    "    if step%10 == 0:\n",
    "        examples_per_sec = batch_size / duration\n",
    "        sec_per_batch = float(duration)\n",
    "        format_str=('step %d,loss%.2f(%.1f examples/sec; %.3f sec/batch)')\n",
    "        print(format_str % (step,loss_value,examples_per_sec,sec_per_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_examples = 10000\n",
    "import math\n",
    "num_iter = int(math.ceil(num_examples / batch_size))\n",
    "true_count = 0\n",
    "total_sample_out = num_iter * batch_size\n",
    "step = 0\n",
    "while step < num_iter:\n",
    "    image_batch,label_batch = sess.run([images_test,labels_test])\n",
    "    predictions = sess.run([top_k_op],feed_dict={image_holder:image_batch,label_holder:label_batch})\n",
    "    true_count += np.sum(predictions)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision @ 1 = 0.531\n"
     ]
    }
   ],
   "source": [
    "precision = true_count / total_sample_out\n",
    "print('precision @ 1 = %.3f'%precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.036"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1018*0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
